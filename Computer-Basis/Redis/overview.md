# 1	持久化
## 1.1	AOF
将数据写到内存中后，写到aof日志中，这个日志最终会保存到磁盘，但是会先保存到内存缓冲区，然后保存到磁盘，提供了三种策略：
- 立即写
- 后台每隔一秒写一次
- 由操作系统控制，redis不控制什么时候写到磁盘
### 1.1.1	AOF重写
当aof日志太大，就会触发aof重写压缩数据：读取aof文件中所有键值对，然后用一条命令写到新的aof日志，主要就是保留最终状态，比如，aof有这两条日志
- set name = 1
- set name = 2
就会只保留set name = 2

重写由后台子进程运行，用新进程的好处：
- 父进程依旧可以提供服务
- 和父进程共享的数据只读，避免了和父进程数据竞争
用新进程流程：
- 使用fork创建子进程，这个子进程会把父进程的页表复制给子进程，这时父子进程公用物理内存，而物理内存会被标记为只读的
- 当父进程或者子进程向公用内存写时，触发写保护中断，写保护中断函数中进行物理内存复制，然后重新映射父子进程中的虚拟内存到这个物理页，并将父子进程设置为可读写
### 1.1.2	重写缓冲区
因为子进程在重写的时候父进程还在写，会导致主进程的数据和子进程不一样，所以主进程在重写期间写时的流程：
- 将执行后的命令写到aof缓冲区
- 将执行后的命令写到aof重写缓冲区
这样对重写进程也能获取到写数据的命令

### 1.1.3	重写完成
重写子进程发送一个信号给父进程，父进程处理：
- 将重写缓冲区的命令追加到压缩后的aof文件
- 修改压缩后的aof文件名，覆盖未压缩的aof文件
## 1.2	RDB快照
保存内存中的**全部**数据到磁盘，有两个命令：
- save：由主进程执行
- bgsave：子进程执行
### 1.2.1	bgsave期间主进程修改数据
修改的数据不会被记录到RDB中，RDB只是针对一个时刻的备份

还要注意写时复制复制太多内容导致占用太多内存：
- rdb期间物理内存是父子进程共享的，如果父进程修改了共享物理内存中的数据，发生写时复制，这个写时复制可能会比较大

## 1.3	混合持久化
aof保存的事命令恢复得一个一个执行，速度慢；RDB恢复快，但是如果频率太低会丢数据，频率高一方面消耗性能，另一方面很难避免丢数据
### 1.3.1	混合持久化流程：
- aof重写时子进程先将与主进程共享的数据以RDB形式放到aof文件中
- 重写期间主进程的命令会以aof的形式记录到重写缓冲区，重写缓冲区的命令会在上一步结束后放到同一个aof文件中
所以aof文件实际上会有RDB和aof格式的数据
![[Pasted image 20240914165546.png]]
使用了混合持久化不能兼容4.0之前版本

# 2	Redis集群（高可用）
## 2.1	主从复制
- 主服务器负责写和将命令同步到从服务器
- 从服务器提供读功能和根据主服务器同步来的命令更新自己
因为主服务器不等从服务器完成命令的执行就返回结果，所以可能从服务器没有同步成功
### 2.1.1	第一次同步流程
执行replicaof 主ip 主port
- 从节点向主节点发送psync 命令，并请求主节点的参数runID和offset，主节点收到后回复fullresync，并带着自己的runid和offset
- 主节点开始打包rdb，并发送给从节点，从节点清空自己的数据，加载主节点的rdb，从主节点开始打包rdb到从节点加载完成，主节点的命令都会写到复制缓冲区中
- 主节点收到从节点加载完成的通知后，将复制缓冲区的命令发给从节点
### 2.1.2	从节点断开重连
- 从节点重连后发送psync命令给主节点，并把自己当前已有的日志的offset发给主节点
- 主节点返回continue命令说明接下来增量同步
- 主节点将断链期间的命令同步到从节点
这里用到两个缓存：
- repl_backlog_buffer：一个环形缓存，用与保存主节点当前时间之前的一段时间广播的命令
- replication_buffer：用与发送给从节点的命令
具体流程：
- 主节点收到offset，查看自己的offset和从节点的offset，决定使用全量还是增量同步，主要是通过判断从节点要读取的数据是否在repl_backlog_buffer中
- 如果是增量同步，就将数据从repl_backlog_buffer写到replication_buffer
- ![[Pasted image 20240915233639.png]]
### 2.1.3	应对主从不一致
- 设置一个监控程序，当主从之间同步差距过大就不让客户端连接这个从节点
### 2.1.4	主从切换数据丢失
#### 2.1.4.1	异步复制同步丢失
主节点把回响应给客户端了，但是还没同步到从节点
解决方法：
- 一个参数：min-slaves-max-lag表示如果所有从节点的同步的时间都超过配置值，主节点就停止服务，就是说如果主从同步的时间太长，主机宕机了就会丢失很多数据，限制min-slaves-max-lag的大小可以限制主宕机后丢失的数据量
#### 2.1.4.2	脑裂导致数据丢失
- 主节点与其他节点断链，与客户端是好的，其他节点选出一个新主，然后主节点和其他节点恢复，主节点降级为从，被新主覆盖
解决方法就是减少脑裂


## 2.2	哨兵模式
提供监控主从服务器功能，并提供主从节点故障转移功能
### 2.2.1	工作原理
哨兵是一个运行在特殊模式下的redis进程
### 2.2.2	哨兵判断主节点故障
主观下线：主或从节点没有响应哨兵的PING
客观下线：主节点没有响应哨兵集群中quorum数量节点的ping，只针对主节点，具体流程：
- 一个哨兵发现主节点没响应，询问其他节点
- 如果其他节点中有quorum-1个认为主节点宕机，就认为主节点客观下线
### 2.2.3	哪一个哨兵来做主从切换
首先成为候选者：上一步中判断主节点客观下线的节点是一个候选者
然后成为哨兵leader，发起投票，满足以下两个条件成为哨兵leader
- 获得半数哨兵投票
- 投票数 > 自己的quorum
所以哨兵集群需要至少三个哨兵，quorum设置为集群哨兵数量的一般加一
### 2.2.4	主从节点切换过程
#### 2.2.4.1	选新主
- 过滤掉离线的和网络状态不好的：有一个记录主从节点断链次数的配置项
- 优先级高的直接被选择，每个节点根据服务器性能有一个优先级配置
- 和原主节点同步最多的：slave_repl_offset和主节点最接近的
- id最小的
#### 2.2.4.2	通知从节点
向所有从节点发生slaveof命令
#### 2.2.4.3	通知客户端主节点变换了
客户端从哨兵订阅了频道，主从切换了哨兵会发布变换消息和新主的ip port
#### 2.2.4.4	监视旧主
旧主恢复后变成新主的从节点
### 2.2.5	哨兵集群组件
只需要配置哨兵的quorum，主节点的名称、ip和port
#### 2.2.5.1	哨兵之间感知
哨兵都会订阅主节点上的__sentinel__:hello频道，这样就能感知对方
#### 2.2.5.2	哨兵感知从节点
通过从主节点获取从节点信息
## 2.3	切片集群模式
Redis有16384个hash槽，每个节点纳管一部分hash槽，全部节点要把这些槽分完，有两种分配方式：
- 平均分配
- 手动分配
对于每一个key，先使用crc计算一个值，这个值对16384取模，决定放在哪一个槽，然后在放到纳管槽的节点

## 2.4	脑裂问题
### 2.4.1	问题原因
- 主库和从库链路故障，但是和客户端正常交互，产生新数据
- 哨兵发现主库故障，选出新主，然后主库降级为从节点
- 从节点从新主全量同步数据，新数据被清理
### 2.4.2	解决方法
有两个配置项，联合使用可以避免
- min-slaves-to-write n：主节点至少和n个从节点连接，否则主节点不能写数据
- min-slaves-max-lag t：主从复制不能超过t秒，否则主节点不能写数据

# 3	Redis过期删除和内存淘汰
使用过期字典，如果对一个key设置过期时间，把这个key带上过期时间放到过期字典，后续查询的时候先检测key是否在过期字典中，在的话就与当前时间比较是否过期
## 3.1	定期删除
定期抽样一部分key看看是否过期，如果这部分里面超过一定比例的key过期了，就再次抽样，否则停止抽样
为了避免一次抽样时间太长，可以限制每次抽样的执行时长
内存友好，cpu不友好
## 3.2	惰性删除
当key被访问到了才判断是否过期，如果过期然后删除
导致有的数据一致放在内存中，内存不友好，cpu友好

## 3.3	持久化时处理过期键
### 3.3.1	RDB
- 生成阶段：生成RDB文件时会对key是否过期进行判断，过期的不会加入到RDB文件中
- 载入阶段：
	- 主节点：载入时会判断是否过期，过期不会载入到内存 - 从节点：无论是否过期都会载入，不过主节点会全量同步数据，所以不影响
### 3.3.2	AOF
- 生成阶段：如果生成aof时key还没被删除，会保留到aof文件中，当文件被删除时，会生成一条DEL命令删除
- 重写阶段：会检查是否过期，过期的不会加入重写aof中
### 3.3.3	主从模式中对过期键的处理
- 从节点不会删除过期key，也就是说一个key过期了，只要还没被主节点删除，客户端还是可以访问到

# 4	内存满了
## 4.1	内存淘汰机制
- 不淘汰，直接返回错误
- 在设置了过期时间的数据中淘汰
- 在全局淘汰
## 4.2	LRU
- 最近最少使用
Redis用一个字段存储一个字段最后一次被使用的时间
缓存污染：一次读取了大量数据，这些数据会被认为是访问过，所以会保存在内存中
## 4.3	LFU
最近最不常使用
用一个字段（实际是lru字段的后八位）来记录一个元素被访问的次数
这里假设一个元素如果之前被访问得多，那么之后更可能被访问
### 4.3.1	redis中的lfu实现
字段lru（24位），被分为两部分：
- ldt：上一次访问时间戳
- logc：频次，越小越容易被淘汰
对logc的更改：
- 先衰减：根据ldt距离当前时间差值，差值越大衰减越多
- 再增减：logc越大的值增加越少
有配置项可以控制衰减和增加速率


# 5	Redis缓存设计
## 5.1	缓存雪崩
大量缓存在同一时间失效，然后又有大量请求同时访问数据库造成数据库宕机
### 5.1.1	解决方法
- 打散缓存失效时间：在缓存失效时间的基础上设置一个随机的失效时间，防止大量缓存同时失效
- 设置缓存不过期：用一个后台服务更新缓存数据，保证缓存数据新鲜
	- 业务发现数据不在缓存，就发送一个更新缓存请求到消息队列，后台线程消费消息队列时判断缓存是否存在，不存在就构建缓存
- 设置互斥锁：如果发现请求数据不在缓存中，只允许一个请求来构建缓存（从数据库捞取数据放到缓存），互斥锁也要设置超时时间，防止构建请求一直持有锁导致阻塞
对于redis宕机造成缓存雪崩：
- 限制业务访问
- 构建高可靠集群
## 5.2	缓存击穿
热点数据到期失效，导致业务直接访问数据库
### 5.2.1	解决方法
- 互斥锁：用锁锁住数据，保证同一时间只有一个线程访问数据，没获取到锁的返回空值或者默认值
- 热点数据不设置过期时间：由一个后台线程保证缓存数据新鲜
## 5.3	缓存穿透
数据不在缓存中，也不在数据库中
### 5.3.1	发生原因
- 恶意攻击删除了数据
- 误操作删除了数据
### 5.3.2	解决方法
- 非法请求限制：在api入口处就判断参数是否合理，不合理直接返回错误，避免访问业务
- 设置默认值或者空值：没有数据就返回默认值或者空值
- 使用布隆过滤器：在写入数据库之前先用布隆过滤器做个标记，后面请求的数据在布隆过滤器查不到直接返回错误，不用到数据库了
#### 5.3.2.1	布隆过滤器
- 一个长度为n、初始值为0的位图
- m个hash函数
- 输入x对m个hash函数计算，得到的值对应的位图下标置为1
由于hash冲突可能会有多个输入值对应同样的对位图的设置，所以布隆过滤器判断一个数存在这个数不一定存在，但是判断不存在那就一定不存在

# 6	缓存更新策略
## 6.1	旁路缓存
### 6.1.1	写策略
- 请求先修改数据库数据，再删除缓存，**不能倒过来**
如果倒过来：
- 请求A请求把数据由1更新到2，先删除缓存
- 这时请求B请求发现缓存不命中，于是把数据库中的1放到缓存
- 然后A把数据库中的1更新到2
- 此时数据库中是2，缓存中是1
不倒过来其实也会有问题：
- A查询数据发现缓存未命中，于是查询数据库中的值为1
- 在A还没把数据写到缓存时，B来把数据库中的1改成2，然后删除缓存
- A把1写回缓存
- 此时缓存中是1，数据库中是2
但是实际中操作缓存会快很多，也就是不太可能B中已经把数据改成2了， A还没把1写到缓存
### 6.1.2	读策略
- 如果读取的数据命中，直接返回
- 没命中，从数据库读，然后将数据写到缓存，再返回用户
### 6.1.3	适合场景
- 读多写少，写多会频繁清理缓存
如果对缓存命中率要求高：
- 更新数据的时候更新缓存，不过加一个分布式锁
- 给缓存加一个短的过期时间
## 6.2	读穿
缓存不命中由缓存组件负责从数据库中查
## 6.3	写穿
- 如果缓存命中，直接更新缓存，然后缓存组件负责更新数据库并告知应用
- 不命中，应用直接更新数据库
## 6.4	写回
写的时候不更新到数据库，只更新缓存，并把缓存标记成脏的， 下一次要写再判断是不是脏的，脏的先写入到数据库然后再将新的写请求写入缓存

## 6.5	数据库和缓存一致性
整体策略：先修改数据库，再删缓存
### 6.5.1	流程
- 将binlog日志采集发送到mq队列
- 编写一个简单的缓存删除的消息者，订阅binlog日志，它的任务就是根据log删除缓存
- 删除后通过ack机制确认缓存已经删除后，才给消息队列回确认消息，这里一定要缓存删除成功后再回，否则删除不成功都没法重试
- 以上属于异步操作

# 7	Redis处理大key
不是key大，是key对应的值大
标准：
- string超过10K
- hash、list、set、zset超过5000个
## 7.1	大key影响
- 客户端阻塞
- 网络阻塞
- 阻塞工作线程：在删除大key时
- 分布不均：有大key的槽会占用更多内存
### 7.1.1	大key对持久化的影响
写回时：
- 只有always会影响，阻塞主线程一会儿
重写时：
- 创建重写子进程会因为复制主进程页表到子进程阻塞主线程一会儿，优化方法
	- 控制redis单例的内存大小
	- 如果redis只是用作缓存，不关心数据安全，可以关闭aof重写
	- 主从架构中调大repl-backlog-size，避免主节点频繁全量同步，全量同步会创建rdb文件，会使用fork
写时复制时：
- 主线程对大key写，导致写时复制，内存中有两份大key
- 开启内存大页的写时复制更是雪上加霜

## 7.2	大key查找
- redis自身的bigkeys参数
- scan
- rdbtools
## 7.3	大key删除
- 异步删除
	- 可以配置自动异步删除
- 分批删除
- 用unlink删除大key
# 8	redis管道
- 一次执行多个命令，是客户端提供的

# 9	redis事务
## 9.1	不支持事务
- 虽然有discard，但是discard用于主动放弃事务
- 也不保证原子性
### 9.1.1	原因
- 不符合redis简单的设计原则
- 生产环境中很少需要回滚

# 10	redis实现分布式锁
## 10.1	10.1 加锁
### 10.1.1	命令：set lock_key client_unique_id NX PX 10000
- lock_key：锁key
- client_unique_id：客户端的唯一标识
- NX：**只有在没有这个lock_key的时候才能添加成功**
- PX：超时时间，防止客户端持有太长时间
## 10.2	解锁
- 需要用lua脚本来保证原子操作
- 需要带上客户端的唯一id，只有解锁的是加锁的id才能解锁，满足锁的条件：锁只能被持有者释放
## 10.3	缺点
- 超时时间不好设置：由于客户端处理时间太长锁超时了被释放后被另一个客户端持有
	- 可以设置一个守护线程续约，直到主线程
- 主从模式中，如果主节点还没将数据同步给从节点就宕机了，其他客户端可以获取锁
## 10.4	redLock
让客户端和多个redis请求加锁
### 10.4.1	流程
- 客户端获取当前时间
- 客户端按顺序向多个redis节点请求加锁，每次请求
	- 设置一个加锁操作超时时间，主要是为了避免节点宕机一直加不了阻塞，这个时间要远小于锁超时时间
- 客户端获取锁的条件
	- 从 > 一半的节点加锁成功
	- 然后获取当前时间计算整个加锁过程的时间，客户端加锁过程时间 < 锁超时时间
- 客户端拿到锁，然后看一下剩余时间是否够用，不够就释放锁，重新获取锁
