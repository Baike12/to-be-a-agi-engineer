### 归一化
- 减小数据之间的尺度差异、使梯度下降更平滑，训练收敛更快
- 减小梯度振荡幅度，有利于避免梯度消失或者梯度爆炸
- 不会破坏数据之间的可比较性
### 批量归一化
- 主要用于CV
- 对一个批量的图像在通道上进行归一化，得到归一化的特征图
- 认为相同维度上的特征具有相同的分布
- 归一化是线性操作，不会对样本之间在同一个特征上的关系产生破坏，会对特征之间的关系造成破坏
- 在NLP中使用批量归一化不仅没有意义，而且由于句子长度不一样导致某些特征在某些样本中不存在
### 层归一化
- 主要用于NLP
- 对一个样本进行归一化
- 认为一个样本中的不同特征具有相同分布
- 对句子中的词进行归一化，保留一个词与句子中其他句子的相关性
- 可以看作BN的转置版
- 对批量大小不敏感